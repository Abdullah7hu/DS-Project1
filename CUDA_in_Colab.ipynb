{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install CUDA C++ plugin for Colab:\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntOgKF_-y0SV",
        "outputId": "9140d338-1410-4dba-d422-c6f34183f459"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect selected GPU and its NVIDA architecture:\n",
        "import subprocess\n",
        "gpu_info = subprocess.getoutput(\"nvidia-smi --query-gpu=name,compute_cap --format=csv,noheader,nounits\")\n",
        "if \"not found\" in gpu_info.lower(): raise RuntimeError(\"Error: No GPU found. Please select a GPU runtime environment.\")\n",
        "gpu_name, compute_cap = map(str.strip, gpu_info.split(','))\n",
        "gpu_arch = f\"sm_{compute_cap.replace('.', '')}\"\n",
        "\n",
        "print(f\"{'GPU Name':<15}: {gpu_name}\")\n",
        "print(f\"{'Architecture':<15}: {gpu_arch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVqh0baiO15d",
        "outputId": "212763b8-d78f-4532-b056-890842095946"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Name       : Tesla T4\n",
            "Architecture   : sm_75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda -c \"--gpu-architecture $gpu_arch\"\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello_kernel() {\n",
        "    int blockId = blockIdx.x;\n",
        "    int threadId = threadIdx.x;\n",
        "    int globalId = threadId + blockId * blockDim.x;\n",
        "\n",
        "    printf(\"Hello from block %d, thread %d (global thread %d)\\n\", blockId, threadId, globalId);\n",
        "}\n",
        "\n",
        "int main() {\n",
        "\n",
        "     printf(\"Hello\\n\");\n",
        "\n",
        "     int arr[] = {1,2,3,4,5,6,7,8,5,6,4,3,2,1};\n",
        "\n",
        "     int i =0;\n",
        "    int Counter =0;\n",
        "     for(i=0;i<sizeof(arr)/sizeof(arr[0]);i++){\n",
        "         printf(\"%d\\n\", arr[i]);\n",
        "     }\n",
        "     printf(\"%d\\n\", Counter);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    int numBlocks = 2;\n",
        "    int threadsPerBlock = 4;\n",
        "\n",
        "    hello_kernel<<<numBlocks, threadsPerBlock>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HW8N8RXzCTc",
        "outputId": "3e754384-93ad-492c-9460-0f7b6d15f56c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "5\n",
            "6\n",
            "4\n",
            "3\n",
            "2\n",
            "1\n",
            "0\n",
            "Hello from block 0, thread 0 (global thread 0)\n",
            "Hello from block 0, thread 1 (global thread 1)\n",
            "Hello from block 0, thread 2 (global thread 2)\n",
            "Hello from block 0, thread 3 (global thread 3)\n",
            "Hello from block 1, thread 0 (global thread 4)\n",
            "Hello from block 1, thread 1 (global thread 5)\n",
            "Hello from block 1, thread 2 (global thread 6)\n",
            "Hello from block 1, thread 3 (global thread 7)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}