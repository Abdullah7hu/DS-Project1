{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install CUDA C++ plugin for Colab:\n",
        "!pip install nvcc4jupyter\n",
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntOgKF_-y0SV",
        "outputId": "1408461b-174b-4331-c593-e66dcd9d079f"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nvcc4jupyter in /usr/local/lib/python3.12/dist-packages (1.2.1)\n",
            "The nvcc4jupyter extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc4jupyter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Detect selected GPU and its NVIDA architecture:\n",
        "import subprocess\n",
        "gpu_info = subprocess.getoutput(\"nvidia-smi --query-gpu=name,compute_cap --format=csv,noheader,nounits\")\n",
        "if \"not found\" in gpu_info.lower(): raise RuntimeError(\"Error: No GPU found. Please select a GPU runtime environment.\")\n",
        "gpu_name, compute_cap = map(str.strip, gpu_info.split(','))\n",
        "gpu_arch = f\"sm_{compute_cap.replace('.', '')}\"\n",
        "\n",
        "print(f\"{'GPU Name':<15}: {gpu_name}\")\n",
        "print(f\"{'Architecture':<15}: {gpu_arch}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVqh0baiO15d",
        "outputId": "735aa56f-71a9-4ef9-81b1-67c9199bdd43"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Name       : Tesla T4\n",
            "Architecture   : sm_75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HW8N2RXzCTc",
        "outputId": "4c0a5a38-5491-40a8-9cd0-45dc7b2804c4"
      },
      "source": [
        "%%cuda -c \"--gpu-architecture $gpu_arch\"\n",
        "\n",
        "#include <time.h>\n",
        "#include <stdio.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "__global__ void bitonic_stage(int *data, int n, int i, int j){\n",
        "\n",
        "    int k = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (k >= n) return;\n",
        "\n",
        "    int comp_dist = 1 << j; // Distance for comparison (e.g., 1, 2, 4)\n",
        "    int partner = k ^ comp_dist;    // Partner index using XOR\n",
        "\n",
        "    // Ensure we only process each pair once (k should be the lower-indexed thread)\n",
        "    if (k >= partner) return;\n",
        "    if (partner >= n) return; // Ensure partner is within bounds\n",
        "\n",
        "    // Determine sorting direction for the overall bitonic sequence of length 2^(i+1).\n",
        "    // If the (i+1)-th bit of 'k' is 0, sort ascending for this block. Else descending.\n",
        "    int ascending_block_dir = ((k & (1 << (i + 1))) == 0);\n",
        "\n",
        "    int a = data[k];\n",
        "    int b = data[partner];\n",
        "\n",
        "    // Conditional swap: if (ascending_block_dir is true AND a > b) OR (ascending_block_dir is false AND a < b)\n",
        "    if (ascending_block_dir == (a > b)) {\n",
        "        data[k]       = b;\n",
        "        data[partner] = a;\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "void bitonic_sort_gpu(int *h_arr, int n){\n",
        "\n",
        "    int *d_arr;\n",
        "    cudaMalloc(&d_arr, n * sizeof(int));\n",
        "    cudaMemcpy(d_arr, h_arr, n * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threads = 256;\n",
        "    int blocks  = (n + threads - 1) / threads;\n",
        "\n",
        "    // steps = log2(n) for n power of 2\n",
        "    int steps = 0;\n",
        "    for (int tmp = n; tmp > 1; tmp >>= 1) {\n",
        "        steps++;\n",
        "    }\n",
        "\n",
        "    for (int i = 1; i <= steps; i++) { // i: 1-indexed stage length (1 to steps)\n",
        "        for (int j = i; j >= 1; j--) { // j: 1-indexed comparison distance (i down to 1)\n",
        "            // Convert to 0-indexed parameters for the kernel call\n",
        "            bitonic_stage<<<blocks, threads>>>(d_arr, n, i - 1, j - 1);\n",
        "\n",
        "        }cudaDeviceSynchronize();\n",
        "    }\n",
        "\n",
        "    cudaMemcpy(h_arr, d_arr, n * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "    cudaFree(d_arr);\n",
        "}\n",
        "\n",
        "\n",
        "int is_bitonic(int arr[], int n) {\n",
        "\n",
        "    int i = 0;\n",
        "    int increasing = 0;\n",
        "    int decreasing = 0;\n",
        "\n",
        "    // Check increasing part\n",
        "    while (i < n - 1 && arr[i] <= arr[i + 1]) {\n",
        "        increasing = 1;\n",
        "        i++;\n",
        "    }\n",
        "    // Check decreasing part\n",
        "    while (i < n - 1 && arr[i] >= arr[i + 1]) {\n",
        "        decreasing = 1;\n",
        "        i++;\n",
        "    }\n",
        "    // if array increases then decreases then it's bitonic\n",
        "    if (increasing && decreasing && i == n - 1) {\n",
        "        return 1;\n",
        "    }\n",
        "    // case where sequence decreases then increases:\n",
        "    i = 0;\n",
        "    increasing = 0;\n",
        "    decreasing = 0;\n",
        "\n",
        "    // Check the decreasing part first\n",
        "    while (i < n - 1 && arr[i] >= arr[i + 1]) {\n",
        "        decreasing = 1;\n",
        "        i++;\n",
        "    }\n",
        "\n",
        "    // Check the increasing part after decreasing part\n",
        "    while (i < n - 1 && arr[i] <= arr[i + 1]) {\n",
        "        increasing = 1;\n",
        "        i++;\n",
        "    }\n",
        "\n",
        "    // If we have an decreasing part followed by an increasing part then it's bitonic\n",
        "    if (decreasing && increasing && i == n - 1) {\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "int main(){\n",
        "\n",
        "\n",
        "\n",
        "    // Array size MUST be a power of 2\n",
        "    int arr[] = {10, 30, 50, 120, 210, 190, 140, 45,42,37,36,34,34,23,11,3};\n",
        "    int n = sizeof(arr) / sizeof(arr[0]);\n",
        "\n",
        "    if((n > 0) && ((n & (n - 1)) == 0) ){\n",
        "\n",
        "\n",
        "     // printf(\"The size of the Array size is to the power of 2\\n\");\n",
        "      int count = 0;\n",
        "      printf(\"Unsorted: \");\n",
        "      for (int i = 0; i < n; i++) {\n",
        "          printf(\"%d \", arr[i]);\n",
        "          count++;\n",
        "      }\n",
        "    printf(\"\\n\");\n",
        "     printf(\"%d\\n\" , count);\n",
        "\n",
        "    if(is_bitonic(arr,n)){\n",
        "    bitonic_sort_gpu(arr, n);\n",
        "\n",
        "    printf(\"Sorted:   \");\n",
        "    for (int i = 0; i < n; i++) {\n",
        "        printf(\"%d \", arr[i]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "\n",
        "    }\n",
        "\n",
        "    else{\n",
        "            printf(\"Array is not a bitonic sequence\");\n",
        "\n",
        "    }\n",
        "    }\n",
        "    else{\n",
        "        printf(\"Array size is not a power of 2\\n\");\n",
        "    }\n",
        "    return 0;\n",
        "}"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsorted: 10 30 50 120 210 190 140 45 42 37 36 34 34 23 11 3 \n",
            "16\n",
            "Sorted:   3 10 11 23 30 34 34 36 37 42 45 50 120 140 190 210 \n",
            "\n"
          ]
        }
      ]
    }
  ]
}